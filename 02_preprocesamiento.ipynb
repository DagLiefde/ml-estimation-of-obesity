{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocesamiento de Datos\n",
        "\n",
        "Se hace una distribución de 70% para train (con validación cruzada) y 30% para test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Librerías importadas correctamente\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import pickle\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Librerías importadas correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Dataset cargado exitosamente\n",
            "  - Forma del dataset: (2111, 17)\n",
            "  - Columnas: ['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'NObeyesdad']\n",
            "\n",
            "Primeras 3 filas:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>family_history_with_overweight</th>\n",
              "      <th>FAVC</th>\n",
              "      <th>FCVC</th>\n",
              "      <th>NCP</th>\n",
              "      <th>CAEC</th>\n",
              "      <th>SMOKE</th>\n",
              "      <th>CH2O</th>\n",
              "      <th>SCC</th>\n",
              "      <th>FAF</th>\n",
              "      <th>TUE</th>\n",
              "      <th>CALC</th>\n",
              "      <th>MTRANS</th>\n",
              "      <th>NObeyesdad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.62</td>\n",
              "      <td>64.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>no</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.52</td>\n",
              "      <td>56.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>77.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Frequently</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
              "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
              "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
              "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
              "\n",
              "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
              "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
              "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
              "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
              "\n",
              "                  MTRANS     NObeyesdad  \n",
              "0  Public_Transportation  Normal_Weight  \n",
              "1  Public_Transportation  Normal_Weight  \n",
              "2  Public_Transportation  Normal_Weight  "
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cargar el dataset\n",
        "df = pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')\n",
        "\n",
        "print(f\" Dataset cargado exitosamente\")\n",
        "print(f\"  - Forma del dataset: {df.shape}\")\n",
        "print(f\"  - Columnas: {list(df.columns)}\")\n",
        "print(f\"\\nPrimeras 3 filas:\")\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores faltantes por columna:\n",
            "No hay valores faltantes\n"
          ]
        }
      ],
      "source": [
        "# Verificar valores faltantes\n",
        "print(f\"Valores faltantes por columna:\")\n",
        "missing = df.isnull().sum()\n",
        "print(missing[missing > 0] if missing.sum() > 0 else \"No hay valores faltantes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculamos el IMC (BMI en inglés) a partir de Weight y Height, y se eliminan estas últimas dos \n",
        "\n",
        "\n",
        "IMC = Peso (kg) / Altura (m)²\n",
        "\n",
        "Las clases de obesidad están basadas en rangos de IMC:\n",
        "- Insufficient_Weight: IMC < 18.5\n",
        "- Normal_Weight: 18.5 ≤ IMC < 25\n",
        "- Overweight_Level_I: 25 ≤ IMC < 27\n",
        "- Overweight_Level_II: 27 ≤ IMC < 30\n",
        "- Obesity_Type_I: 30 ≤ IMC < 35\n",
        "- Obesity_Type_II: 35 ≤ IMC < 40\n",
        "- Obesity_Type_III: IMC ≥ 40\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculando IMC (Índice de Masa Corporal)...\n",
            " IMC calculado\n",
            "  - Rango de IMC: 13.00 - 50.81\n",
            "  - Media de IMC: 29.70\n",
            "\n",
            "Ejemplos de cálculo:\n",
            "   Height  Weight        BMI           NObeyesdad\n",
            "0    1.62    64.0  24.386526        Normal_Weight\n",
            "1    1.52    56.0  24.238227        Normal_Weight\n",
            "2    1.80    77.0  23.765432        Normal_Weight\n",
            "3    1.80    87.0  26.851852   Overweight_Level_I\n",
            "4    1.78    89.8  28.342381  Overweight_Level_II\n",
            "\n",
            "Eliminando variables Weight y Height...\n",
            "   Variables eliminadas\n",
            "  - Columnas restantes: 16\n",
            "\n",
            " Variable objetivo separada: 'NObeyesdad'\n",
            "  - Forma de y: (2111,)\n",
            "  - Forma de X: (2111, 15)\n",
            "\n",
            "ANÁLISIS DE TIPOS DE VARIABLES:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Variables Numéricas (7):\n",
            "  - Age: min=14.00, max=61.00, media=24.31\n",
            "  - FCVC: min=1.00, max=3.00, media=2.42\n",
            "  - NCP: min=1.00, max=4.00, media=2.69\n",
            "  - CH2O: min=1.00, max=3.00, media=2.01\n",
            "  - FAF: min=0.00, max=3.00, media=1.01\n",
            "  - TUE: min=0.00, max=2.00, media=0.66\n",
            "  - BMI: min=13.00, max=50.81, media=29.70\n",
            "\n",
            "Variables Categóricas (8):\n",
            "  - Gender: 2 valores únicos -> ['Female', 'Male']...\n",
            "  - family_history_with_overweight: 2 valores únicos -> ['yes', 'no']...\n",
            "  - FAVC: 2 valores únicos -> ['no', 'yes']...\n",
            "  - CAEC: 4 valores únicos -> ['Sometimes', 'Frequently', 'Always', 'no']...\n",
            "  - SMOKE: 2 valores únicos -> ['no', 'yes']...\n",
            "  - SCC: 2 valores únicos -> ['no', 'yes']...\n",
            "  - CALC: 4 valores únicos -> ['no', 'Sometimes', 'Frequently', 'Always']...\n",
            "  - MTRANS: 5 valores únicos -> ['Public_Transportation', 'Walking', 'Automobile', 'Motorbike', 'Bike']...\n"
          ]
        }
      ],
      "source": [
        "# Calcular IMC (BMI) = Weight (kg) / Height (m)²\n",
        "print(\"Calculando IMC (Índice de Masa Corporal)...\")\n",
        "df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
        "\n",
        "print(f\" IMC calculado\")\n",
        "print(f\"  - Rango de IMC: {df['BMI'].min():.2f} - {df['BMI'].max():.2f}\")\n",
        "print(f\"  - Media de IMC: {df['BMI'].mean():.2f}\")\n",
        "\n",
        "# Mostrar algunos ejemplos antes de eliminar\n",
        "print(f\"\\nEjemplos de cálculo:\")\n",
        "print(df[['Height', 'Weight', 'BMI', 'NObeyesdad']].head())\n",
        "\n",
        "# Eliminar Weight y Height (ya no las necesitamos)\n",
        "print(f\"\\nEliminando variables Weight y Height...\")\n",
        "df = df.drop(columns=['Weight', 'Height'])\n",
        "print(f\"   Variables eliminadas\")\n",
        "print(f\"  - Columnas restantes: {len(df.columns)}\")\n",
        "\n",
        "# Variable objetivo\n",
        "target_column = 'NObeyesdad'\n",
        "y = df[target_column].copy()\n",
        "\n",
        "# Características (todas las columnas excepto la objetivo)\n",
        "X = df.drop(columns=[target_column])\n",
        "\n",
        "print(f\"\\n Variable objetivo separada: '{target_column}'\")\n",
        "print(f\"  - Forma de y: {y.shape}\")\n",
        "print(f\"  - Forma de X: {X.shape}\")\n",
        "\n",
        "# Identificar tipos de variables\n",
        "print(f\"\\nANÁLISIS DE TIPOS DE VARIABLES:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Variables numéricas (ya son números)\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"\\nVariables Numéricas ({len(numeric_cols)}):\")\n",
        "for col in numeric_cols:\n",
        "    print(f\"  - {col}: min={X[col].min():.2f}, max={X[col].max():.2f}, media={X[col].mean():.2f}\")\n",
        "\n",
        "# Variables categóricas (objetos/strings)\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "print(f\"\\nVariables Categóricas ({len(categorical_cols)}):\")\n",
        "for col in categorical_cols:\n",
        "    unique_vals = X[col].unique()\n",
        "    print(f\"  - {col}: {len(unique_vals)} valores únicos -> {list(unique_vals)[:5]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding de variables categóricas\n",
        "\n",
        "Label Encoding para variables binarias, One-Hot Encoding para variables categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables Binarias (Label Encoding): ['Gender', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC']\n",
            "Variables Multi-Categoría (One-Hot Encoding): ['CAEC', 'CALC', 'MTRANS']\n"
          ]
        }
      ],
      "source": [
        "# Crear una copia para trabajar\n",
        "X_encoded = X.copy()\n",
        "\n",
        "# Identificar variables binarias (solo 2 valores)\n",
        "binary_cols = []\n",
        "multi_cat_cols = []\n",
        "\n",
        "for col in categorical_cols:\n",
        "    n_unique = X[col].nunique()\n",
        "    if n_unique == 2:\n",
        "        binary_cols.append(col)\n",
        "    else:\n",
        "        multi_cat_cols.append(col)\n",
        "\n",
        "print(f\"Variables Binarias (Label Encoding): {binary_cols}\")\n",
        "print(f\"Variables Multi-Categoría (One-Hot Encoding): {multi_cat_cols}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Aplicando Label Encoding a variables binarias...\n",
            "   Gender: {'Female': 0, 'Male': 1}\n",
            "   family_history_with_overweight: {'no': 0, 'yes': 1}\n",
            "   FAVC: {'no': 0, 'yes': 1}\n",
            "   SMOKE: {'no': 0, 'yes': 1}\n",
            "   SCC: {'no': 0, 'yes': 1}\n"
          ]
        }
      ],
      "source": [
        "# 4.1: Label Encoding para variables binarias\n",
        "print(f\"\\nAplicando Label Encoding a variables binarias...\")\n",
        "label_encoders = {}\n",
        "\n",
        "for col in binary_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X[col])\n",
        "    label_encoders[col] = le\n",
        "    print(f\"   {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Aplicando One-Hot Encoding a variables multi-categoría...\n",
            "   Variables codificadas:\n",
            "    - Antes: 8 variables categóricas\n",
            "    - Después: 25 variables totales\n",
            "    - Nuevas columnas creadas: 13\n",
            "\n",
            "  Ejemplo de nuevas columnas (primeras 5):\n",
            "    - CAEC_Always\n",
            "    - CAEC_Frequently\n",
            "    - CAEC_Sometimes\n",
            "    - CAEC_no\n",
            "    - CALC_Always\n"
          ]
        }
      ],
      "source": [
        "# 4.2: One-Hot Encoding para variables multi-categoría\n",
        "print(f\"\\nAplicando One-Hot Encoding a variables multi-categoría...\")\n",
        "\n",
        "# Usar pandas get_dummies (más simple que sklearn para este caso)\n",
        "X_encoded = pd.get_dummies(X_encoded, columns=multi_cat_cols, prefix=multi_cat_cols, drop_first=False)\n",
        "\n",
        "print(f\"   Variables codificadas:\")\n",
        "print(f\"    - Antes: {len(categorical_cols)} variables categóricas\")\n",
        "print(f\"    - Después: {X_encoded.shape[1]} variables totales\")\n",
        "print(f\"    - Nuevas columnas creadas: {X_encoded.shape[1] - len(numeric_cols) - len(binary_cols)}\")\n",
        "\n",
        "# Mostrar algunas columnas nuevas\n",
        "new_cols = [col for col in X_encoded.columns if any(mc in col for mc in multi_cat_cols)]\n",
        "print(f\"\\n  Ejemplo de nuevas columnas (primeras 5):\")\n",
        "for col in new_cols[:5]:\n",
        "    print(f\"    - {col}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalización/Estandarización de Variables Numéricas\n",
        "\n",
        "Estandarización (Z-score normalization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables a estandarizar (12):\n",
            "  ['Age', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'BMI', 'Gender', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC']\n",
            "\n",
            " Scaler creado (se aplicará después de dividir train/test)\n",
            "  - Tipo: StandardScaler (Z-score normalization)\n",
            "  - Fórmula: z = (x - μ) / σ\n",
            "\n",
            " Estadísticas ANTES de estandarizar (primeras 3 variables):\n",
            "  Age:\n",
            "    - Media: 24.3126\n",
            "    - Desv. Est.: 6.3460\n",
            "    - Min: 14.0000\n",
            "    - Max: 61.0000\n",
            "  FCVC:\n",
            "    - Media: 2.4190\n",
            "    - Desv. Est.: 0.5339\n",
            "    - Min: 1.0000\n",
            "    - Max: 3.0000\n",
            "  NCP:\n",
            "    - Media: 2.6856\n",
            "    - Desv. Est.: 0.7780\n",
            "    - Min: 1.0000\n",
            "    - Max: 4.0000\n"
          ]
        }
      ],
      "source": [
        "# Identificar columnas numéricas (después del encoding)\n",
        "# Las columnas numéricas originales + las binarias codificadas\n",
        "numeric_cols_to_scale = numeric_cols + binary_cols\n",
        "\n",
        "print(f\"Variables a estandarizar ({len(numeric_cols_to_scale)}):\")\n",
        "print(f\"  {numeric_cols_to_scale}\")\n",
        "\n",
        "# Crear el scaler (pero NO aplicarlo aún - lo haremos después de dividir)\n",
        "# Esto es importante: NO debemos estandarizar antes de dividir train/test\n",
        "# porque podríamos \"filtrar\" información del test al train\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "print(f\"\\n Scaler creado (se aplicará después de dividir train/test)\")\n",
        "print(f\"  - Tipo: StandardScaler (Z-score normalization)\")\n",
        "print(f\"  - Fórmula: z = (x - μ) / σ\")\n",
        "\n",
        "# Mostrar estadísticas antes de estandarizar\n",
        "print(f\"\\n Estadísticas ANTES de estandarizar (primeras 3 variables):\")\n",
        "for col in numeric_cols_to_scale[:3]:\n",
        "    print(f\"  {col}:\")\n",
        "    print(f\"    - Media: {X_encoded[col].mean():.4f}\")\n",
        "    print(f\"    - Desv. Est.: {X_encoded[col].std():.4f}\")\n",
        "    print(f\"    - Min: {X_encoded[col].min():.4f}\")\n",
        "    print(f\"    - Max: {X_encoded[col].max():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### División de Datos (70-30) con Estratificación\n",
        "\n",
        "Divide los datos en Train (70%) y Test (30%) manteniendo la proporción de clases en ambos conjuntos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " División completada:\n",
            "  - Train: 1477 registros (70.0%)\n",
            "  - Test: 634 registros (30.0%)\n",
            "  - Características: 25\n"
          ]
        }
      ],
      "source": [
        "# División estratificada\n",
        "# random_state: Para reproducibilidad (mismos resultados cada vez)\n",
        "# stratify: Mantiene proporción de clases\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded,\n",
        "    y,\n",
        "    test_size=0.30,  # 30% para test\n",
        "    random_state=42,  # Semilla para reproducibilidad\n",
        "    stratify=y  # Estratificación por clases\n",
        ")\n",
        "\n",
        "print(f\"\\n División completada:\")\n",
        "print(f\"  - Train: {X_train.shape[0]} registros ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"  - Test: {X_test.shape[0]} registros ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"  - Características: {X_train.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Verificación de estratificación:\n",
            "\n",
            "Distribución en Train:\n",
            "  Insufficient_Weight      :  190 (12.86%)\n",
            "  Normal_Weight            :  201 (13.61%)\n",
            "  Obesity_Type_I           :  245 (16.59%)\n",
            "  Obesity_Type_II          :  208 (14.08%)\n",
            "  Obesity_Type_III         :  227 (15.37%)\n",
            "  Overweight_Level_I       :  203 (13.74%)\n",
            "  Overweight_Level_II      :  203 (13.74%)\n",
            "\n",
            "Distribución en Test:\n",
            "  Insufficient_Weight      :   82 (12.93%)\n",
            "  Normal_Weight            :   86 (13.56%)\n",
            "  Obesity_Type_I           :  106 (16.72%)\n",
            "  Obesity_Type_II          :   89 (14.04%)\n",
            "  Obesity_Type_III         :   97 (15.30%)\n",
            "  Overweight_Level_I       :   87 (13.72%)\n",
            "  Overweight_Level_II      :   87 (13.72%)\n",
            "\n",
            " Verificación: Las proporciones son similares en ambos conjuntos\n"
          ]
        }
      ],
      "source": [
        "# Verificar estratificación\n",
        "print(f\"\\n Verificación de estratificación:\")\n",
        "print(f\"\\nDistribución en Train:\")\n",
        "train_dist = y_train.value_counts().sort_index()\n",
        "train_pct = (y_train.value_counts(normalize=True) * 100).sort_index()\n",
        "for clase in train_dist.index:\n",
        "    print(f\"  {clase:25s}: {train_dist[clase]:4d} ({train_pct[clase]:5.2f}%)\")\n",
        "\n",
        "print(f\"\\nDistribución en Test:\")\n",
        "test_dist = y_test.value_counts().sort_index()\n",
        "test_pct = (y_test.value_counts(normalize=True) * 100).sort_index()\n",
        "for clase in test_dist.index:\n",
        "    print(f\"  {clase:25s}: {test_dist[clase]:4d} ({test_pct[clase]:5.2f}%)\")\n",
        "\n",
        "# Verificar que las proporciones son similares\n",
        "print(f\"\\n Verificación: Las proporciones son similares en ambos conjuntos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Estandarización de datos después de dividir para evitar leakage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Ajustando scaler con datos de train...\n",
            " Estandarización aplicada\n",
            "\n",
            " Estadísticas DESPUÉS de estandarizar (primeras 3 variables):\n",
            "  Age:\n",
            "    - Media: 0.000000 (debe ser ~0)\n",
            "    - Desv. Est.: 1.000339 (debe ser ~1)\n",
            "    - Min: -1.3202\n",
            "    - Max: 5.8305\n",
            "  FCVC:\n",
            "    - Media: -0.000000 (debe ser ~0)\n",
            "    - Desv. Est.: 1.000339 (debe ser ~1)\n",
            "    - Min: -2.7065\n",
            "    - Max: 1.0833\n",
            "  NCP:\n",
            "    - Media: -0.000000 (debe ser ~0)\n",
            "    - Desv. Est.: 1.000339 (debe ser ~1)\n",
            "    - Min: -2.1733\n",
            "    - Max: 1.6959\n"
          ]
        }
      ],
      "source": [
        "# Ajustar scaler SOLO con datos de train\n",
        "print(f\"\\n Ajustando scaler con datos de train...\")\n",
        "scaler.fit(X_train[numeric_cols_to_scale])\n",
        "\n",
        "# Aplicar transformación\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "X_train_scaled[numeric_cols_to_scale] = scaler.transform(X_train[numeric_cols_to_scale])\n",
        "X_test_scaled[numeric_cols_to_scale] = scaler.transform(X_test[numeric_cols_to_scale])\n",
        "\n",
        "print(f\" Estandarización aplicada\")\n",
        "\n",
        "# Mostrar estadísticas después de estandarizar\n",
        "print(f\"\\n Estadísticas DESPUÉS de estandarizar (primeras 3 variables):\")\n",
        "for col in numeric_cols_to_scale[:3]:\n",
        "    print(f\"  {col}:\")\n",
        "    print(f\"    - Media: {X_train_scaled[col].mean():.6f} (debe ser ~0)\")\n",
        "    print(f\"    - Desv. Est.: {X_train_scaled[col].std():.6f} (debe ser ~1)\")\n",
        "    print(f\"    - Min: {X_train_scaled[col].min():.4f}\")\n",
        "    print(f\"    - Max: {X_train_scaled[col].max():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding variable objetivo\n",
        "\n",
        "```\n",
        "0: Insufficient_Weight\n",
        "1: Normal_Weight\n",
        "2: Overweight_Level_I\n",
        "3: Overweight_Level_II\n",
        "4: Obesity_Type_I\n",
        "5: Obesity_Type_II\n",
        "6: Obesity_Type_III\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Variable objetivo codificada:\n",
            "  Mapeo de clases:\n",
            "    0: Insufficient_Weight\n",
            "    1: Normal_Weight\n",
            "    2: Overweight_Level_I\n",
            "    3: Overweight_Level_II\n",
            "    4: Obesity_Type_I\n",
            "    5: Obesity_Type_II\n",
            "    6: Obesity_Type_III\n",
            "\n",
            "  Distribución en Train (codificada):\n",
            "0    190\n",
            "1    201\n",
            "2    245\n",
            "3    208\n",
            "4    227\n",
            "5    203\n",
            "6    203\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  Distribución en Test (codificada):\n",
            "0     82\n",
            "1     86\n",
            "2    106\n",
            "3     89\n",
            "4     97\n",
            "5     87\n",
            "6     87\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Definir orden ordinal\n",
        "ordinal_order = [\n",
        "    'Insufficient_Weight',\n",
        "    'Normal_Weight',\n",
        "    'Overweight_Level_I',\n",
        "    'Overweight_Level_II',\n",
        "    'Obesity_Type_I',\n",
        "    'Obesity_Type_II',\n",
        "    'Obesity_Type_III'\n",
        "]\n",
        "\n",
        "# Crear encoder ordinal\n",
        "target_encoder = LabelEncoder()\n",
        "target_encoder.fit(ordinal_order)\n",
        "\n",
        "# Aplicar encoding\n",
        "y_train_encoded = pd.Series(target_encoder.transform(y_train), index=y_train.index)\n",
        "y_test_encoded = pd.Series(target_encoder.transform(y_test), index=y_test.index)\n",
        "\n",
        "print(f\"\\n Variable objetivo codificada:\")\n",
        "print(f\"  Mapeo de clases:\")\n",
        "for i, clase in enumerate(ordinal_order):\n",
        "    print(f\"    {i}: {clase}\")\n",
        "\n",
        "print(f\"\\n  Distribución en Train (codificada):\")\n",
        "print(y_train_encoded.value_counts().sort_index())\n",
        "\n",
        "print(f\"\\n  Distribución en Test (codificada):\")\n",
        "print(y_test_encoded.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Guardado de datos preprocesados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Guardando datos preprocesados...\n",
            "   Datos guardados en 'data/processed/'\n"
          ]
        }
      ],
      "source": [
        "# Crear directorio si no existe\n",
        "os.makedirs('data/processed', exist_ok=True)\n",
        "os.makedirs('models/preprocessing', exist_ok=True)\n",
        "\n",
        "# Guardar datos preprocesados\n",
        "print(f\"\\n Guardando datos preprocesados...\")\n",
        "\n",
        "# Guardar como CSV (para inspección)\n",
        "X_train_scaled.to_csv('data/processed/X_train.csv', index=False)\n",
        "X_test_scaled.to_csv('data/processed/X_test.csv', index=False)\n",
        "y_train_encoded.to_csv('data/processed/y_train.csv', index=False)\n",
        "y_test_encoded.to_csv('data/processed/y_test.csv', index=False)\n",
        "\n",
        "# Guardar también las versiones originales (sin codificar) para referencia\n",
        "y_train.to_csv('data/processed/y_train_original.csv', index=False)\n",
        "y_test.to_csv('data/processed/y_test_original.csv', index=False)\n",
        "\n",
        "print(f\"   Datos guardados en 'data/processed/'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Guardando transformadores...\n",
            "   Transformadores guardados en 'models/preprocessing/'\n"
          ]
        }
      ],
      "source": [
        "# Guardar transformadores\n",
        "print(f\"\\n Guardando transformadores...\")\n",
        "\n",
        "with open('models/preprocessing/scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "with open('models/preprocessing/target_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(target_encoder, f)\n",
        "\n",
        "with open('models/preprocessing/label_encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoders, f)\n",
        "\n",
        "# Guardar información sobre las columnas\n",
        "preprocessing_info = {\n",
        "    'numeric_cols': numeric_cols,\n",
        "    'binary_cols': binary_cols,\n",
        "    'multi_cat_cols': multi_cat_cols,\n",
        "    'numeric_cols_to_scale': numeric_cols_to_scale,\n",
        "    'ordinal_order': ordinal_order,\n",
        "    'n_features': X_train_scaled.shape[1]\n",
        "}\n",
        "\n",
        "with open('models/preprocessing/preprocessing_info.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessing_info, f)\n",
        "\n",
        "print(f\"   Transformadores guardados en 'models/preprocessing/'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resumen\n",
        "\n",
        "1. Carga y exploración del dataset original\n",
        "2. Identificación de tipos de variables (numéricas vs categóricas)\n",
        "3. Encoding de variables\n",
        "4. Estandarización de variables numéricas\n",
        "5. División estratificada** 70-30 (Train/Test)\n",
        "6. Encoding ordinal** de variable objetivo\n",
        "7. Guardado de datos preprocesados y transformadores\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
